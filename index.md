---

layout: single
classes: wide
author_profile: true
title: ''
seo_title: "Alessio Devoto | Applied Researcher at NVIDIA â€“ Efficient & Interpretable AI"
excerpt: "Applied Researcher at NVIDIA working on efficient, adaptive, and interpretable machine learning."
seo_description: "Alessio Devoto is an Applied Researcher at NVIDIA, focusing on efficient training and inference for language and vision models, adaptive computation, and AI interpretability."

---

## Hi ğŸ‘‹

ğŸ‘¨â€ğŸ”¬ I am an Applied Researcher at NVIDIA, working with the Applied Agents Research and Kaggle Grandmasters teams.

ğŸ“ I completed my PhD in Data Science at Sapienza University of Rome, where my research focused on efficient and interpretable machine learning, under the supervision of [Simone Scardapane](https://www.sscardapane.it).

ğŸ´ I was previously a visiting researcher at Edinburgh NLP, supervised by [Pasquale Minervini](https://neuralnoise.com/).

ğŸ”¬ My research background spans both Computer Vision and Natural Language Processing, focusing on making AI systems more efficient and interpretable. My current research interests include efficient training and inference for Language and Vision Models [[1](https://arxiv.org/abs/2406.11430),[2](https://arxiv.org/abs/2408.08670)], AI Interpretability [[3](https://arxiv.org/abs/2410.15999), [4](https://arxiv.org/abs/2501.03432)], Adaptive & Conditional Computation methods [[2](https://arxiv.org/abs/2408.08670), [5](https://arxiv.org/abs/2312.10193)].

## Blog
ğŸ“ I maintain a small blog where I share code tutorials and insights on various deep learning topics, feel free to [take a look](https://alessiodevoto.github.io/blog/)!nsights** on deep learning, transformers, and efficiency-oriented methods. Feel free to [take a look](https://alessiodevoto.github.io/blog/)!

## Beyond Research

* ğŸ“ˆ Training as a **certified Life & Business Coach** (International Coaching Federation)
* ğŸ‡ªğŸ‡¸ Former **Erasmus student** at [Universidad PolitÃ©cnica de Valencia](http://www.upv.es/es), Spain
* ğŸ›ï¸ Passionate about languages (even [dead ones!](https://www.sssscomic.com/comicpages/196.jpg)) â€” I teach Ancient Greek and Latin to high school and college students

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

## Latest Publications

These are some of my recent publications. For a complete list, pleasecheck  my [Google Scholar](https://scholar.google.com/citations?user=er31rp0AAAAJ&hl=en).

* [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731) (2025)
* [Expected Attention: KV Cache Compression by Estimating Attention from Future Queries](https://arxiv.org/abs/2510.00636) (2025)
* [Adaptive Computation Modules: Granular Conditional Computation For Efficient Inference](https://arxiv.org/abs/2312.10193) (AAAI 2025)
* [A Simple and Effective $$ L_2 $$ Norm-Based Strategy for KV Cache Compression](https://arxiv.org/abs/2406.11430) (EMNLP 2024)
* [Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression](https://arxiv.org/abs/2503.02812)(SLLM @ ICLR 2025)
* [Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering](https://arxiv.org/abs/2410.15999) (NAACL 2025)
* [Mixture-of-Experts Graph Transformers for Interpretable Particle Collision Detection](https://arxiv.org/abs/2501.03432) (Nature Scientific Reports, 2025)
* [Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning](https://arxiv.org/abs/2408.08670) (Neurocomputing vol. 654, 2024)
* [Are We Done With MMLU?](https://arxiv.org/abs/2406.04127) (NAACL 2025)

## Contacts

Iâ€™m active on social media â€” [LinkedIn](https://www.linkedin.com/in/alessio-devoto/), [Bluesky](https://bsky.app/profile/alessiodevoto.bsky.social), [Twitter/X](https://x.com/devoto_alessio) â€” and always happy to chat.
